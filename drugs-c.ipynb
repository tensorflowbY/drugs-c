{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "\n",
    "data_dir = \"C:\\\\Users\\\\batuy\\\\Documents\\\\VS Code\\\\drugs_classification\\\\Data Combined\"\n",
    "train_dir = \"train_data\"\n",
    "test_dir = \"test_data\"\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her bir kategori için veri ayırma işlemi\n",
    "for category in os.listdir(data_dir):\n",
    "    category_path = os.path.join(data_dir, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        # Kategoriye ait tüm dosyaları listeleme\n",
    "        files = os.listdir(category_path)\n",
    "        train_files, test_files = train_test_split(files, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Eğitim ve test dizinlerine bu kategori için alt dizinler oluşturma\n",
    "        train_category_dir = os.path.join(train_dir, category)\n",
    "        test_category_dir = os.path.join(test_dir, category)\n",
    "        \n",
    "        os.makedirs(train_category_dir, exist_ok=True)\n",
    "        os.makedirs(test_category_dir, exist_ok=True)\n",
    "        \n",
    "        # Dosyaları ilgili dizinlere taşıma\n",
    "        for file in train_files:\n",
    "            shutil.copy(os.path.join(category_path, file), os.path.join(train_category_dir, file))\n",
    "        \n",
    "        for file in test_files:\n",
    "            shutil.copy(os.path.join(category_path, file), os.path.join(test_category_dir, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   rotation_range=40,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data_gen.flow_from_directory(directory=train_dir,\n",
    "                                               batch_size=64,\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               target_size=img_size)\n",
    "\n",
    "test_data = test_data_gen.flow_from_directory(directory=test_dir,\n",
    "                                              batch_size=64,\n",
    "                                              class_mode=\"categorical\",\n",
    "                                              target_size=img_size)\n",
    "\n",
    "base_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(350, activation=\"relu\")(x)\n",
    "prediction = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ana veri dizini\n",
    "target_1 = \"C:\\\\Users\\\\batuy\\\\Documents\\\\VS Code\\\\drugs_classification\\\\train_data\"\n",
    "\n",
    "target_list = os.listdir(target_1)\n",
    "\n",
    "random_path = random.choice(target_list)\n",
    "\n",
    "klasor_yolu = os.path.join(target_1, random_path)\n",
    "\n",
    "dosya_listesi = os.listdir(klasor_yolu)\n",
    "\n",
    "resimler = [resim for resim in dosya_listesi if resim.endswith(\".png\") or resim.endswith(\".jpg\")]\n",
    "\n",
    "random_img = random.sample(resimler, 6)\n",
    "\n",
    "for resim in random_img:\n",
    "    print(\"Path: \", os.path.join(klasor_yolu, resim)[62:74])\n",
    "    resim_yolu = os.path.join(klasor_yolu, resim)\n",
    "    img = plt.imread(resim_yolu)\n",
    "    print(f\"Shape: \", {img.shape})\n",
    "    plt.imshow(img)\n",
    "    plt.title(resim)   \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "rlp = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, min_lr=0.000001, patience=2)\n",
    "# model_check = ModelCheckpoint(filepath=\"project.keras\", monitor=\"val_loss\", verbose=1 ,save_best_only=True)\n",
    "callbacks = [rlp]\n",
    "\n",
    "# train_data_2, val_data = train_test_split(train_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data,\n",
    "                    validation_data=test_data,\n",
    "                    epochs=30,\n",
    "                    batch_size=64,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
